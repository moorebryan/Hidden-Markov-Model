{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Hidden Markov Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #initialize probability for forward propogation at first time interval\n",
    "    def forward_initial(self, Observables, B):\n",
    "        alpha_t=[0]*B.shape[0]\n",
    "        index=Observables[0]\n",
    "        for i in range(0,B.shape[0]):\n",
    "            alpha_t[i]=PI[i]*B[i][index]\n",
    "        return alpha_t\n",
    "    \n",
    "    # Calculate Forward Propogation Probabilities\n",
    "    def forward_propagation(self,PI, A, B,Observables):\n",
    "        forward_proba=np.zeros([PI.shape[0],Observables.shape[0]])\n",
    "        alpha_t = self.forward_initial(Observables,B)\n",
    "        forward_proba[:,0] = alpha_t\n",
    "        for time in range(1,Observables.shape[0]):\n",
    "            #compute an inner product with the first entry for inner summation\n",
    "            index=Observables[time]\n",
    "            temp=np.asarray(alpha_t)\n",
    "            inner_product=[np.dot(temp,A[:,item])*B[item][index] for item in range(A.shape[1])]\n",
    "            forward_proba[:,time]=np.asarray(inner_product)\n",
    "            alpha_t=inner_product\n",
    "        alpha = forward_proba # Rename\n",
    "        return alpha\n",
    "    \n",
    "    # Calculate Normalized Forward Propogation Probabilities\n",
    "    def forward_normalized(self,PI, A, B,Observables):\n",
    "        forward_proba=np.zeros([PI.shape[0],len(Observables)])\n",
    "        alpha_t = self.forward_initial(Observables,B)\n",
    "        c=np.zeros(len(Observables))\n",
    "        currScaleFact = 1/np.array(alpha_t).sum(axis=0)\n",
    "        c[0] = currScaleFact\n",
    "        alpha_t = [elem * currScaleFact for elem in alpha_t]\n",
    "        forward_proba[:,0] = alpha_t\n",
    "        for time in range(1,len(Observables)):\n",
    "            #compute an inner product with the first entry for inner summation\n",
    "            index=Observables[time]\n",
    "            temp=np.asarray(alpha_t)\n",
    "            inner_product=[np.dot(temp,A[:,item])*B[item][index] for item in range(A.shape[1])]\n",
    "            # normalize this inner product\n",
    "            currScaleFact = 1/np.array(inner_product).sum(axis=0)\n",
    "            c[time] = currScaleFact\n",
    "            inner_product = [elem * currScaleFact for elem in inner_product]\n",
    "            forward_proba[:,time]=np.asarray(inner_product)\n",
    "            alpha_t=inner_product\n",
    "        alpha = forward_proba # Rename\n",
    "        return alpha,c\n",
    "    \n",
    "    #Initialize probability for forward propogation at first time interval\n",
    "    def backward_initial(self, Observables, B):\n",
    "        beta_t=[0]*B.shape[0]\n",
    "        index=Observables[-1]\n",
    "        for i in range(0,B.shape[0]):\n",
    "            beta_t[i]=1\n",
    "        return beta_t\n",
    "    \n",
    "    # Calculate Backward Propogation Probabilities\n",
    "    def backward_propagation(self,PI, A, B,Observables):\n",
    "        backward_proba=np.empty([PI.shape[0],len(Observables)])\n",
    "        beta_t = self.backward_initial(Observables,B)\n",
    "        backward_proba[:,-1] = beta_t\n",
    "        for time in reversed(range(0,len(Observables)-1)): # Goes over each time\n",
    "            index=Observables[time+1] # index for current observation\n",
    "            temp=np.asarray(beta_t) # Holds previous beta column\n",
    "            inner_product=np.empty(PI.shape[0])\n",
    "            for i in range(0,PI.shape[0]): # Go through each row to fill in new beta column\n",
    "                temp_product = 0\n",
    "                for j in range(0,PI.shape[0]): # Go through each row for summation from older beta column\n",
    "                    temp_product+=B[j,index]*temp[j]*A[i,j]\n",
    "                inner_product[i]=temp_product\n",
    "            backward_proba[:,time]=np.asarray(inner_product)\n",
    "            beta_t=inner_product\n",
    "        beta = backward_proba # Rename\n",
    "        return beta\n",
    "    \n",
    "    # Calculate Normalized Backward Propogation Probabilities\n",
    "    def backward_normalized(self,PI, A, B,Observables,c):\n",
    "        backward_proba=np.empty([PI.shape[0],len(Observables)])\n",
    "        beta_t = self.backward_initial(Observables,B)\n",
    "        # Normalize beta_t using c\n",
    "        currScaleFact = c[len(Observables)-1]\n",
    "        beta_t = [elem * currScaleFact for elem in beta_t]\n",
    "        backward_proba[:,-1] = beta_t\n",
    "        for time in reversed(range(0,len(Observables)-1)):\n",
    "            #compute an inner product with the first entry\n",
    "            index=Observables[time+1]\n",
    "            temp=np.asarray(beta_t)\n",
    "            inner_product=np.empty(PI.shape[0])\n",
    "            for i in range(0,PI.shape[0]): # Go through each row to fill in new beta column\n",
    "                temp_product = 0\n",
    "                for j in range(0,PI.shape[0]): # Go through each row for summation from older beta column\n",
    "                    temp_product+=B[j,index]*temp[j]*A[i,j]\n",
    "                inner_product[i]=temp_product\n",
    "            # Normalize inner_product\n",
    "            currScaleFact = c[time]\n",
    "            inner_product = [elem * currScaleFact for elem in inner_product]\n",
    "            backward_proba[:,time]=np.asarray(inner_product)\n",
    "            beta_t=inner_product\n",
    "        beta = backward_proba # Rename\n",
    "        return beta\n",
    "    \n",
    "    # Calculates probability for unnormalized forward observations occuring\n",
    "    def evaluation_unnormalized(self,alpha):\n",
    "        #grab last column of alpha\n",
    "        eval_last=alpha[:,-1]\n",
    "        eval_proba=eval_last.sum(axis=0)\n",
    "        return eval_proba\n",
    "    \n",
    "    # Calculates log probabilities for normalized forward observations occuring\n",
    "    def evaluation_normalized(self,c):\n",
    "        apply_function=lambda t:np.log(t)\n",
    "        c_log=np.vectorize(apply_function)\n",
    "        eval_proba_norm=c_log(c)\n",
    "        eval_proba_norm=-eval_proba_norm.sum(axis=0)\n",
    "        return eval_proba_norm\n",
    "    \n",
    "    # Calculate smoothed probability for observations sequence occuring\n",
    "    def smoothed_probability(self,alpha,beta):\n",
    "        smoothed_proba=np.array([[alpha[i, j]*beta[i,j] for j in range(alpha.shape[1])]\n",
    "                     for i in range(alpha.shape[0])])\n",
    "        sum_sp=smoothed_proba.sum(axis=0)\n",
    "        scale_function=lambda t:1/t\n",
    "        c_func=np.vectorize(scale_function)\n",
    "        c=c_func(sum_sp)\n",
    "        sp_normalized=np.array([[smoothed_proba[i, j]*c[j] for j in range(alpha.shape[1])]\n",
    "                     for i in range(alpha.shape[0])])\n",
    "        smoothed_proba=sp_normalized\n",
    "        return smoothed_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Initial Stage Probability Vector<br>\n",
    "This holds the initial probabilities for each hidden state, here we considered only two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial hidden state probability vector is below:\n",
      "\n",
      "   Depressed  Healthy\n",
      "0        0.5      0.5\n"
     ]
    }
   ],
   "source": [
    "# Our two hidden states are depressed and healthy\n",
    "states = ['Depressed','Healthy']\n",
    "\n",
    "# Below is the initial stage probabilities for each state\n",
    "PI = np.array([.5,.5])\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "PI_df = pd.DataFrame(PI,index=states)\n",
    "print('The initial hidden state probability vector is below:\\n')\n",
    "print(PI_df.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Hidden State Transition Matrix<br>\n",
    "This contains the probabilities of transitioning from one hidden state, given on side, to another hidden state, given along the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hidden state transition matrix is below:\n",
      "\n",
      "          Depressed Healthy\n",
      "Depressed     0.999   0.001\n",
      "Healthy         0.2     0.8\n"
     ]
    }
   ],
   "source": [
    "# equals transition probability matrix of changing states given a state\n",
    "# matrix is size (M x M) where M is number of states\n",
    "#first  I make data frame then  I convert to matrix A\n",
    "A_df = pd.DataFrame(columns=states, index=states)\n",
    "A_df.loc[states[0]] = [0.999, 0.001]\n",
    "A_df.loc[states[1]] = [0.2 ,0.8]\n",
    "A_df.head()\n",
    "A=np.asarray(A_df)\n",
    "\n",
    "print('The hidden state transition matrix is below:\\n')\n",
    "print(A_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create matrix of observation (emission) probabilities<br>\n",
    "This contains the probability of the given emission (given on top) from a given hidden state (given on side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix of emission probabilities is below:\n",
      "\n",
      "              0     1    2    3    4\n",
      "Depressed  0.05  0.35  0.2  0.2  0.2\n",
      "Healthy     0.5   0.1  0.3  0.1    0\n"
     ]
    }
   ],
   "source": [
    "# Below is the legend connecting observed actions with representative integers:\n",
    "# Movement - 0\n",
    "# Passive Social Networking - 1\n",
    "# Active Social Networking - 2\n",
    "# Texting - 3\n",
    "# Access Psych Health App/Sites - 4\n",
    "\n",
    "# These are the states which can be observed\n",
    "states_obs=['0','1','2','3','4']\n",
    "\n",
    "B_df = pd.DataFrame(columns=states_obs, index=states)\n",
    "B_df.loc[states[0]] = [0.05, 0.35, 0.2,0.2,0.2]\n",
    "B_df.loc[states[1]] = [0.5, 0.1, 0.3,0.1,0]\n",
    "B=np.asarray(B_df)\n",
    "\n",
    "print('The matrix of emission probabilities is below:\\n')\n",
    "print(B_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing the code below creates a vector containing a set of randomly observed actions of chosen length<br>\n",
    "A more realistic example would come from actual data so there would be an actual pattern to uncover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the observation sequence used in this analysis (note row is marked with index 0 at far left)\n",
      "\n",
      " 0  2  4  4  4  1  4  4  2  1\n"
     ]
    }
   ],
   "source": [
    "len_obs = 10 # Length of observation sequence to create\n",
    "\n",
    "# This is a randomly created dummy vector, which for real dataset would be replaced\n",
    "Observables = np.random.randint(5, size=len_obs)\n",
    "Observables=np.array(Observables)\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "Observables_df=pd.DataFrame(Observables)\n",
    "print('Below is the observation sequence used in this analysis (note row is marked with index 0 at far left)\\n')\n",
    "print(Observables_df.transpose().to_string(index=False,header=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the HMM class so for testing below is same as just calling a previously created definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMM_class = HMM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the unnormalized forward variable matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the unnormalized forward variable matrix:\n",
      "\n",
      "              0         1         2         3         4         5         6  \\\n",
      "Depressed  0.10  0.045465  0.009564  0.000507  0.000148  0.000041  0.000003   \n",
      "Healthy    0.15  0.012010  0.002896  0.001163  0.000279  0.000067  0.000027   \n",
      "\n",
      "                  7             8             9  \n",
      "Depressed  0.000002  8.063373e-08  1.614291e-08  \n",
      "Healthy    0.000000  8.071445e-10  2.179048e-10  \n"
     ]
    }
   ],
   "source": [
    "alpha=HMM_class.forward_propagation(PI, A, B,Observables)\n",
    "print('Below is the unnormalized forward variable matrix:\\n')\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "alpha_df=pd.DataFrame(alpha, index=[states])\n",
    "print(alpha_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the normalized forward variable matrix and display normalization constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the normalized forward variable matrix:\n",
      "\n",
      "             0        1        2         3         4         5         6    7  \\\n",
      "Depressed  0.4  0.79104  0.76758  0.303431  0.345987  0.377597  0.091473  1.0   \n",
      "Healthy    0.6  0.20896  0.23242  0.696569  0.654013  0.622403  0.908527  0.0   \n",
      "\n",
      "                  8         9  \n",
      "Depressed  0.990089  0.986681  \n",
      "Healthy    0.009911  0.013319  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Below are the scaling factors used in the normalization procedure (note row is marked with index 0 at far left):\n",
      "\n",
      "     0         1         2         3         4         5         6          7  \\\n",
      "0  4.0  4.349717  4.612633  7.461752  3.909978  3.962662  3.646508  18.309208   \n",
      "\n",
      "           8         9  \n",
      "0  19.821606  4.977802  \n"
     ]
    }
   ],
   "source": [
    "[alpha_norm,c]=HMM_class.forward_normalized(PI, A, B,Observables)\n",
    "print('Below is the normalized forward variable matrix:\\n')\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "alpha_norm_df=pd.DataFrame(alpha_norm, index=[states])\n",
    "print(alpha_norm_df)\n",
    "print('\\n');print('\\n');print('\\n') # 3 empty spaces before displaying the scaling constants\n",
    "\n",
    "print('Below are the scaling factors used in the normalization procedure (note row is marked with index 0 at far left):\\n')\n",
    "c_df=pd.DataFrame(c)\n",
    "print(c_df.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the unnormalized backward variable matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the unnormalized backward variable matrix:\n",
      "\n",
      "                      0             1             2         3         4  \\\n",
      "Depressed  1.527562e-08  4.334564e-08  2.095015e-07  0.000004  0.000020   \n",
      "Healthy    9.888832e-08  1.198177e-06  4.957486e-06  0.000012  0.000048   \n",
      "\n",
      "                  5         6         7       8    9  \n",
      "Depressed  0.000101  0.002025  0.010135  0.2001  1.0  \n",
      "Healthy    0.000182  0.000405  0.114001  0.2800  1.0  \n"
     ]
    }
   ],
   "source": [
    "beta = HMM_class.backward_propagation(PI,A,B,Observables)\n",
    "print('Below is the unnormalized backward variable matrix:\\n')\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "beta_df=pd.DataFrame(beta, index=[states])\n",
    "print(beta_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the normalized backward variable matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the normalized backward variable matrix:\n",
      "\n",
      "                  0          1          2         3         4         5  \\\n",
      "Depressed  0.933671   0.662339   0.735972  3.100600  2.072411  2.645660   \n",
      "Healthy    6.044219  18.308638  17.415487  9.361502  4.882091  4.761655   \n",
      "\n",
      "                   6           7          8         9  \n",
      "Depressed  13.339580   18.309208  19.743473  4.977802  \n",
      "Healthy     2.670587  205.946621  27.627049  4.977802  \n"
     ]
    }
   ],
   "source": [
    "beta_norm = HMM_class.backward_normalized(PI, A, B,Observables,c)\n",
    "print('Below is the normalized backward variable matrix:\\n')\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "beta_norm_df=pd.DataFrame(beta_norm, index=[states])\n",
    "print(beta_norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate indicated probabilities for observation sequence using the normalized forward variable matrix and the log probability for the normalized forward variable matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unnormalized probability of the given observation sequence is: 1.64E-08\n",
      "\n",
      "\n",
      "The normalized log-probability of the given observation sequence is: -17.928377\n"
     ]
    }
   ],
   "source": [
    "eval_proba=HMM_class.evaluation_unnormalized(alpha)\n",
    "print(\"The unnormalized probability of the given observation sequence is: %.2E\" %Decimal(eval_proba))\n",
    "print('\\n')\n",
    "\n",
    "eval_proba_norm=HMM_class.evaluation_normalized(c)\n",
    "print(\"The normalized log-probability of the given observation sequence is: %f\" %eval_proba_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Forward-Backward Smoothing this calculates the smoothed probability matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the smoothed probability matrix:\n",
      "\n",
      "                  0         1         2         3         4         5  \\\n",
      "Depressed  0.093367  0.120453  0.122472  0.126085  0.183384  0.252102   \n",
      "Healthy    0.906633  0.879547  0.877528  0.873915  0.816616  0.747898   \n",
      "\n",
      "                  6    7         8         9  \n",
      "Depressed  0.334623  1.0  0.986186  0.986681  \n",
      "Healthy    0.665377  0.0  0.013814  0.013319  \n"
     ]
    }
   ],
   "source": [
    "smoothed_proba=HMM_class.smoothed_probability(alpha,beta)\n",
    "print('Below is the smoothed probability matrix:\\n')\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "smoothed_proba_df=pd.DataFrame(smoothed_proba, index=[states])\n",
    "print(smoothed_proba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
