{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "\n",
    "# The below suppresses all warnings in the notebook\n",
    "# Only leave this uncommented for display purposes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Hidden Markov Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    #initialize probability for forward propogation at first time interval\n",
    "    def forward_initial(self, Observables, B):\n",
    "        alpha_t=[0]*B.shape[0]\n",
    "        index=Observables[0]\n",
    "        for i in range(0,B.shape[0]):\n",
    "            alpha_t[i]=PI[i]*B[i][index]\n",
    "        return alpha_t\n",
    "    \n",
    "    # Calculate Forward Propogation Probabilities\n",
    "    def forward_propagation(self,PI, A, B,Observables):\n",
    "        forward_proba=np.zeros([PI.shape[0],Observables.shape[0]])\n",
    "        alpha_t = self.forward_initial(Observables,B)\n",
    "        forward_proba[:,0] = alpha_t\n",
    "        for time in range(1,Observables.shape[0]):\n",
    "            #compute an inner product with the first entry for inner summation\n",
    "            index=Observables[time]\n",
    "            temp=np.asarray(alpha_t)\n",
    "            inner_product=[np.dot(temp,A[:,item])*B[item][index] for item in range(A.shape[1])]\n",
    "            forward_proba[:,time]=np.asarray(inner_product)\n",
    "            alpha_t=inner_product\n",
    "        alpha = forward_proba # Rename\n",
    "        return alpha\n",
    "    \n",
    "    # Calculate Normalized Forward Propogation Probabilities\n",
    "    def forward_normalized(self,PI, A, B,Observables):\n",
    "        forward_proba=np.zeros([PI.shape[0],len(Observables)])\n",
    "        alpha_t = self.forward_initial(Observables,B)\n",
    "        c=np.zeros(len(Observables))\n",
    "        currScaleFact = 1/np.array(alpha_t).sum(axis=0)\n",
    "        c[0] = currScaleFact\n",
    "        alpha_t = [elem * currScaleFact for elem in alpha_t]\n",
    "        forward_proba[:,0] = alpha_t\n",
    "        for time in range(1,len(Observables)):\n",
    "            #compute an inner product with the first entry for inner summation\n",
    "            index=Observables[time]\n",
    "            temp=np.asarray(alpha_t)\n",
    "            inner_product=[np.dot(temp,A[:,item])*B[item][index] for item in range(A.shape[1])]\n",
    "            # normalize this inner product\n",
    "            currScaleFact = 1/np.array(inner_product).sum(axis=0)\n",
    "            c[time] = currScaleFact\n",
    "            inner_product = [elem * currScaleFact for elem in inner_product]\n",
    "            forward_proba[:,time]=np.asarray(inner_product)\n",
    "            alpha_t=inner_product\n",
    "        alpha = forward_proba # Rename\n",
    "        return alpha,c\n",
    "    \n",
    "    #Initialize probability for forward propogation at first time interval\n",
    "    def backward_initial(self, Observables, B):\n",
    "        beta_t=[0]*B.shape[0]\n",
    "        index=Observables[-1]\n",
    "        for i in range(0,B.shape[0]):\n",
    "            beta_t[i]=1\n",
    "        return beta_t\n",
    "    \n",
    "    # Calculate Backward Propogation Probabilities\n",
    "    def backward_propagation(self,PI, A, B,Observables):\n",
    "        backward_proba=np.empty([PI.shape[0],len(Observables)])\n",
    "        beta_t = self.backward_initial(Observables,B)\n",
    "        backward_proba[:,-1] = beta_t\n",
    "        for time in reversed(range(0,len(Observables)-1)): # Goes over each time\n",
    "            index=Observables[time+1] # index for current observation\n",
    "            temp=np.asarray(beta_t) # Holds previous beta column\n",
    "            inner_product=np.empty(PI.shape[0])\n",
    "            for i in range(0,PI.shape[0]): # Go through each row to fill in new beta column\n",
    "                temp_product = 0\n",
    "                for j in range(0,PI.shape[0]): # Go through each row for summation from older beta column\n",
    "                    temp_product+=B[j,index]*temp[j]*A[i,j]\n",
    "                inner_product[i]=temp_product\n",
    "            backward_proba[:,time]=np.asarray(inner_product)\n",
    "            beta_t=inner_product\n",
    "        beta = backward_proba # Rename\n",
    "        return beta\n",
    "    \n",
    "    # Calculate Normalized Backward Propogation Probabilities\n",
    "    def backward_normalized(self,PI, A, B,Observables,c):\n",
    "        backward_proba=np.empty([PI.shape[0],len(Observables)])\n",
    "        beta_t = self.backward_initial(Observables,B)\n",
    "        # Normalize beta_t using c\n",
    "        currScaleFact = c[len(Observables)-1]\n",
    "        beta_t = [elem * currScaleFact for elem in beta_t]\n",
    "        backward_proba[:,-1] = beta_t\n",
    "        for time in reversed(range(0,len(Observables)-1)):\n",
    "            #compute an inner product with the first entry\n",
    "            index=Observables[time+1]\n",
    "            temp=np.asarray(beta_t)\n",
    "            inner_product=np.empty(PI.shape[0])\n",
    "            for i in range(0,PI.shape[0]): # Go through each row to fill in new beta column\n",
    "                temp_product = 0\n",
    "                for j in range(0,PI.shape[0]): # Go through each row for summation from older beta column\n",
    "                    temp_product+=B[j,index]*temp[j]*A[i,j]\n",
    "                inner_product[i]=temp_product\n",
    "            # Normalize inner_product\n",
    "            currScaleFact = c[time]\n",
    "            inner_product = [elem * currScaleFact for elem in inner_product]\n",
    "            backward_proba[:,time]=np.asarray(inner_product)\n",
    "            beta_t=inner_product\n",
    "        beta = backward_proba # Rename\n",
    "        return beta\n",
    "    \n",
    "    # Calculates probability for unnormalized forward observations occuring\n",
    "    def evaluation_unnormalized(self,alpha):\n",
    "        #grab last column of alpha\n",
    "        eval_last=alpha[:,-1]\n",
    "        eval_proba=eval_last.sum(axis=0)\n",
    "        return eval_proba\n",
    "    \n",
    "    # Calculates log probabilities for normalized forward observations occuring\n",
    "    def evaluation_normalized(self,c):\n",
    "        apply_function=lambda t:np.log(t)\n",
    "        c_log=np.vectorize(apply_function)\n",
    "        eval_proba_norm=c_log(c)\n",
    "        eval_proba_norm=-eval_proba_norm.sum(axis=0)\n",
    "        return eval_proba_norm\n",
    "    \n",
    "    # Calculate smoothed probability for observations sequence occuring\n",
    "    def smoothed_probability(self,alpha,beta):\n",
    "        smoothed_proba=np.array([[alpha[i, j]*beta[i,j] for j in range(alpha.shape[1])]\n",
    "                     for i in range(alpha.shape[0])])\n",
    "        sum_sp=smoothed_proba.sum(axis=0)\n",
    "        scale_function=lambda t:1/t\n",
    "        c_func=np.vectorize(scale_function)\n",
    "        c=c_func(sum_sp)\n",
    "        sp_normalized=np.array([[smoothed_proba[i, j]*c[j] for j in range(alpha.shape[1])]\n",
    "                     for i in range(alpha.shape[0])])\n",
    "        smoothed_proba=sp_normalized\n",
    "        return smoothed_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Initial Stage Probability Vector<br>\n",
    "This holds the initial probabilities for each hidden state, here we considered only two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial hidden state probability vector is below:\n",
      "\n",
      "   Depressed  Healthy\n",
      "0        0.5      0.5\n"
     ]
    }
   ],
   "source": [
    "# Our two hidden states are depressed and healthy\n",
    "states = ['Depressed','Healthy']\n",
    "\n",
    "# Below is the initial stage probabilities for each state\n",
    "PI = np.array([.5,.5])\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "PI_df = pd.DataFrame(PI,index=states)\n",
    "print('The initial hidden state probability vector is below:\\n')\n",
    "print(PI_df.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Hidden State Transition Matrix<br>\n",
    "This contains the probabilities of transitioning from one hidden state, given on side, to another hidden state, given along the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hidden state transition matrix is below:\n",
      "\n",
      "          Depressed Healthy\n",
      "Depressed     0.999   0.001\n",
      "Healthy         0.2     0.8\n"
     ]
    }
   ],
   "source": [
    "# equals transition probability matrix of changing states given a state\n",
    "# matrix is size (M x M) where M is number of states\n",
    "#first  I make data frame then  I convert to matrix A\n",
    "A_df = pd.DataFrame(columns=states, index=states)\n",
    "A_df.loc[states[0]] = [0.999, 0.001]\n",
    "A_df.loc[states[1]] = [0.2 ,0.8]\n",
    "A_df.head()\n",
    "A=np.asarray(A_df)\n",
    "\n",
    "print('The hidden state transition matrix is below:\\n')\n",
    "print(A_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create matrix of observation (emission) probabilities<br>\n",
    "This contains the probability of the given emission (given on top) from a given hidden state (given on side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix of emission probabilities is below:\n",
      "\n",
      "              0     1    2    3    4\n",
      "Depressed  0.05  0.35  0.2  0.2  0.2\n",
      "Healthy     0.5   0.1  0.3  0.1    0\n"
     ]
    }
   ],
   "source": [
    "# Below is the legend connecting observed actions with representative integers:\n",
    "# Movement - 0\n",
    "# Passive Social Networking - 1\n",
    "# Active Social Networking - 2\n",
    "# Texting - 3\n",
    "# Access Psych Health App/Sites - 4\n",
    "\n",
    "# These are the states which can be observed\n",
    "states_obs=['0','1','2','3','4']\n",
    "\n",
    "B_df = pd.DataFrame(columns=states_obs, index=states)\n",
    "B_df.loc[states[0]] = [0.05, 0.35, 0.2,0.2,0.2]\n",
    "B_df.loc[states[1]] = [0.5, 0.1, 0.3,0.1,0]\n",
    "B=np.asarray(B_df)\n",
    "\n",
    "print('The matrix of emission probabilities is below:\\n')\n",
    "print(B_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing the code below creates a vector containing a set of randomly observed actions of chosen length<br>\n",
    "A more realistic example would come from actual data so there would be an actual pattern to uncover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the observation sequence used in this analysis (note row is marked with index 0 at far left)\n",
      "\n",
      " 3  3  4  3  4  4  4  3  0  1\n"
     ]
    }
   ],
   "source": [
    "len_obs = 10 # Length of observation sequence to create\n",
    "\n",
    "# This is a randomly created dummy vector, which for real dataset would be replaced\n",
    "Observables = np.random.randint(5, size=len_obs)\n",
    "Observables=np.array(Observables)\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "Observables_df=pd.DataFrame(Observables)\n",
    "print('Below is the observation sequence used in this analysis (note row is marked with index 0 at far left)\\n')\n",
    "print(Observables_df.transpose().to_string(index=False,header=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the HMM class so for testing below is same as just calling a previously created definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "HMM_class = HMM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the unnormalized forward variable matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the unnormalized forward variable matrix:\n",
      "\n",
      "              0        1         2             3         4         5  \\\n",
      "Depressed  0.10  0.02198  0.004552  9.094904e-04  0.000182  0.000036   \n",
      "Healthy    0.05  0.00401  0.000000  4.552004e-07  0.000000  0.000000   \n",
      "\n",
      "                  6             7             8             9  \n",
      "Depressed  0.000007  1.449518e-06  7.241067e-08  2.538944e-08  \n",
      "Healthy    0.000000  7.254844e-10  1.014953e-09  8.843728e-11  \n"
     ]
    }
   ],
   "source": [
    "alpha=HMM_class.forward_propagation(PI, A, B,Observables)\n",
    "print('Below is the unnormalized forward variable matrix:\\n')\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "alpha_df=pd.DataFrame(alpha, index=[states])\n",
    "print(alpha_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the normalized forward variable matrix and display normalization constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the normalized forward variable matrix:\n",
      "\n",
      "                  0        1    2       3    4    5    6       7         8  \\\n",
      "Depressed  0.666667  0.84571  1.0  0.9995  1.0  1.0  1.0  0.9995  0.986177   \n",
      "Healthy    0.333333  0.15429  0.0  0.0005  0.0  0.0  0.0  0.0005  0.013823   \n",
      "\n",
      "                  9  \n",
      "Depressed  0.996529  \n",
      "Healthy    0.003471  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Below are the scaling factors used in the normalization procedure (note row is marked with index 0 at far left):\n",
      "\n",
      "          0         1         2         3         4         5         6  \\\n",
      "0  6.666667  5.771451  5.709573  5.002501  5.007008  5.005005  5.005005   \n",
      "\n",
      "          7          8         9  \n",
      "0  5.002501  19.751188  2.881937  \n"
     ]
    }
   ],
   "source": [
    "[alpha_norm,c]=HMM_class.forward_normalized(PI, A, B,Observables)\n",
    "print('Below is the normalized forward variable matrix:\\n')\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "alpha_norm_df=pd.DataFrame(alpha_norm, index=[states])\n",
    "print(alpha_norm_df)\n",
    "print('\\n');print('\\n');print('\\n') # 3 empty spaces before displaying the scaling constants\n",
    "\n",
    "print('Below are the scaling factors used in the normalization procedure (note row is marked with index 0 at far left):\\n')\n",
    "c_df=pd.DataFrame(c)\n",
    "print(c_df.transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the unnormalized backward variable matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the unnormalized backward variable matrix:\n",
      "\n",
      "                      0             1         2         3         4         5  \\\n",
      "Depressed  2.234576e-07  1.118294e-06  0.000006  0.000028  0.000140  0.000702   \n",
      "Healthy    6.264238e-08  2.238827e-07  0.000002  0.000006  0.000028  0.000140   \n",
      "\n",
      "                  6         7        8    9  \n",
      "Depressed  0.003512  0.017545  0.34975  1.0  \n",
      "Healthy    0.005782  0.063498  0.15000  1.0  \n"
     ]
    }
   ],
   "source": [
    "beta = HMM_class.backward_propagation(PI,A,B,Observables)\n",
    "print('Below is the unnormalized backward variable matrix:\\n')\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "beta_df=pd.DataFrame(beta, index=[states])\n",
    "print(beta_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the normalized backward variable matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the normalized backward variable matrix:\n",
      "\n",
      "                  0         1         2         3         4         5  \\\n",
      "Depressed  8.770651  6.583913  5.709573  5.004504  5.007008  5.005005   \n",
      "Healthy    2.458697  1.318101  1.600578  1.001903  1.002404  1.002003   \n",
      "\n",
      "                  6          7          8         9  \n",
      "Depressed  5.005005   4.995955  19.908356  2.881937  \n",
      "Healthy    8.239815  18.080961   8.538251  2.881937  \n"
     ]
    }
   ],
   "source": [
    "beta_norm = HMM_class.backward_normalized(PI, A, B,Observables,c)\n",
    "print('Below is the normalized backward variable matrix:\\n')\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "beta_norm_df=pd.DataFrame(beta_norm, index=[states])\n",
    "print(beta_norm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate indicated probabilities for observation sequence using the normalized forward variable matrix and the log probability for the normalized forward variable matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unnormalized probability of the given observation sequence is: 2.55E-08\n",
      "\n",
      "\n",
      "The normalized log-probability of the given observation sequence is: -17.485455\n"
     ]
    }
   ],
   "source": [
    "eval_proba=HMM_class.evaluation_unnormalized(alpha)\n",
    "print(\"The unnormalized probability of the given observation sequence is: %.2E\" %Decimal(eval_proba))\n",
    "print('\\n')\n",
    "\n",
    "eval_proba_norm=HMM_class.evaluation_normalized(c)\n",
    "print(\"The normalized log-probability of the given observation sequence is: %f\" %eval_proba_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Forward-Backward Smoothing this calculates the smoothed probability matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is the smoothed probability matrix:\n",
      "\n",
      "                  0         1    2       3    4    5    6         7         8  \\\n",
      "Depressed  0.877065  0.964763  1.0  0.9999  1.0  1.0  1.0  0.998192  0.994025   \n",
      "Healthy    0.122935  0.035237  0.0  0.0001  0.0  0.0  0.0  0.001808  0.005975   \n",
      "\n",
      "                  9  \n",
      "Depressed  0.996529  \n",
      "Healthy    0.003471  \n"
     ]
    }
   ],
   "source": [
    "smoothed_proba=HMM_class.smoothed_probability(alpha,beta)\n",
    "print('Below is the smoothed probability matrix:\\n')\n",
    "\n",
    "# Convert to pandas dataframe for better output display\n",
    "smoothed_proba_df=pd.DataFrame(smoothed_proba, index=[states])\n",
    "print(smoothed_proba_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
